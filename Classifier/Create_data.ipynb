{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code articles dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code articles dataset\n",
    "import pandas as pd\n",
    "from scrape import get_articles_dataset\n",
    "article_df = get_articles_dataset('datasets/code_articles.csv', limit=1500, start=1001)\n",
    "# article_df = get_articles_dataset('code_articles.csv', limit=1500, start=1001)\n",
    "clean_article = {'X': [str(article) for article in article_df], 'Y': 'productive'}\n",
    "clean_article = pd.DataFrame(clean_article)\n",
    "\n",
    "print(clean_article.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Now I have to say \"Leroy can you please paint ...\n",
      "Name: body, dtype: object\n",
      "                                                        X             Y\n",
      "0       I hate how you cant even say black paint anymo...  unproductive\n",
      "1       What's the difference between a Jew in Nazi Ge...  unproductive\n",
      "2       I recently went to America.... ...and being th...  unproductive\n",
      "3       Brian raises his hand and says, “He’s in Heave...  unproductive\n",
      "4       You hear about the University book store worke...  unproductive\n",
      "...                                                   ...           ...\n",
      "194548  I like a girl with words tattooed on her back....  unproductive\n",
      "194549     I have sexdaily... I mean dyslexia fcuk!!! >_<  unproductive\n",
      "194550  What's the difference between a hippie chick a...  unproductive\n",
      "194551  new family robot A father buys a lie detector ...  unproductive\n",
      "194552  I went to a zoo and there was only one animal....  unproductive\n",
      "\n",
      "[194553 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#reddit jokes dataset\n",
    "reddit_jokes = pd.read_json('datasets/reddit_jokes.json')\n",
    "print(reddit_jokes['body'].head(1))\n",
    "clean_reddit_jokes = {\"X\":[str(reddit_jokes[\"title\"][i])+\" \"+str(reddit_jokes[\"body\"][i]) for i in range(reddit_jokes.shape[0])]}\n",
    "clean_reddit_jokes[\"Y\"] = [\"unproductive\" for i in range(reddit_jokes.shape[0])]\n",
    "clean_reddit_jokes = pd.DataFrame(clean_reddit_jokes)\n",
    "\n",
    "print(clean_reddit_jokes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#website dataset\n",
    "\n",
    "website = pd.read_csv(\"datasets/website.csv\")\n",
    "#print(website.columns)\n",
    "unproductiveSites = [\"Travel\", \"Social Networking and Messaging\", \"Streaming Services\", \"Sports\", \"Photography\", \"News\", \"Health and Fitness\", \"Games\", \"E-Commerce\", \"Forums\", \"Food\", \"Adult\"]\n",
    "\n",
    "clean_website = {\"X\":[str(website[\"cleaned_website_text\"][i]) for i in range(website.shape[0])]}\n",
    "clean_website[\"Y\"] = [\"NAN\"]*website.shape[0]\n",
    "for i in range(website.shape[0]):\n",
    "    if str(website[\"Category\"][i]) in unproductiveSites:\n",
    "        clean_website[\"Y\"][i] = \"unproductive\"\n",
    "    else:\n",
    "        clean_website[\"Y\"][i] = \"productive\"\n",
    "\n",
    "\n",
    "clean_website = pd.DataFrame(clean_website)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = pd.read_csv(\"./datasets/Netflix.csv\")\n",
    "clean_netflix = {\"X\":[str(netflix[\"title\"][i])+\" \"+str(netflix[\"body\"][i]) for i in range(netflix.shape[0])]}\n",
    "clean_netflix[\"Y\"] = [\"unproductive\" for i in range(netflix.shape[0])]\n",
    "clean_netflix = pd.DataFrame(clean_netflix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     X           Y\n",
      "0    5 Best Practices For Writing SQL JoinsSQL (Str...  productive\n",
      "1    Foundation CSS Dropdown MenuFoundation CSS is ...  productive\n",
      "2    Top 20 Excel Shortcuts That You Need To KnowAl...  productive\n",
      "3    Servlet – Fetching ResultServlet is a simple j...  productive\n",
      "4    Suffix Sum ArraySuffix Sum ArrayGiven an array...  productive\n",
      "..                                                 ...         ...\n",
      "494  Python – Get word frequency in percentageGiven...  productive\n",
      "495  How to check the execution time of Python scri...  productive\n",
      "496  React animated loading/splash screen using ‘re...  productive\n",
      "497  Python Program to extract Dictionaries with gi...  productive\n",
      "498  Sum of the first M elements of Array formed by...  productive\n",
      "\n",
      "[499 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./dataframes/article500.csv\")\n",
    "result_new = result.drop(['Unnamed: 0'], axis=1)\n",
    "print(result_new)\n",
    "result_new.to_csv(\"./dataframes/article500.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        X             Y\n",
      "0       official site good hotel accommodation big sav...  unproductive\n",
      "1       expedia hotel book sites like use vacation wor...  unproductive\n",
      "2       tripadvisor hotel book sites like previously d...  unproductive\n",
      "3       cheap flights search compare flights momondo f...  unproductive\n",
      "4       bot create free account create free account si...  unproductive\n",
      "...                                                   ...           ...\n",
      "200413  ML | Natural Language Processing using Deep Le...    productive\n",
      "200414  Python Text To Speech | pyttsx modulepyttsx is...    productive\n",
      "200415  Big Challenges with Big DataThe challenges in ...    productive\n",
      "200416  Program to print Step PatternThe program must ...    productive\n",
      "200417  K length words that can be formed from given c...    productive\n",
      "\n",
      "[200418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clean_article = pd.concat([pd.read_csv(\"./dataframes/article\"+str(x)+\".csv\") for x in range(500,4500,500)], ignore_index=True)\n",
    "clean_research = pd.read_csv(\"./datasets/research_papers_articles.csv\")\n",
    "result = pd.concat([clean_website,clean_reddit_jokes,clean_netflix, clean_article,clean_research], ignore_index=True)\n",
    "\n",
    "print(result)\n",
    "\n",
    "result.to_csv(\"./dataframes/dataset.csv\",  index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
