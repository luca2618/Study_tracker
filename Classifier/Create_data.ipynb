{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\OneDrive\\Skrivebord\\Study_tracker\\Classifier\\Create_data.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/OneDrive/Skrivebord/Study_tracker/Classifier/Create_data.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/OneDrive/Skrivebord/Study_tracker/Classifier/Create_data.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscrape\u001b[39;00m \u001b[39mimport\u001b[39;00m get_articles_dataset\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/OneDrive/Skrivebord/Study_tracker/Classifier/Create_data.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m article_df \u001b[39m=\u001b[39m get_articles_dataset(\u001b[39m'\u001b[39;49m\u001b[39mdatasets/code_articles.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/OneDrive/Skrivebord/Study_tracker/Classifier/Create_data.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clean_article \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39mstr\u001b[39m(article) \u001b[39mfor\u001b[39;00m article \u001b[39min\u001b[39;00m article_df], \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mproductive\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/OneDrive/Skrivebord/Study_tracker/Classifier/Create_data.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m clean_article \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(clean_article)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\OneDrive\\Skrivebord\\Study_tracker\\Classifier\\scrape.py:19\u001b[0m, in \u001b[0;36mget_articles_dataset\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m url \u001b[39m=\u001b[39m row[\u001b[39m3\u001b[39m]\n\u001b[0;32m     18\u001b[0m article \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mstr\u001b[39m(url))\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[39m# Parse the HTML content with BeautifulSoup\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\__init__.py:362\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m    361\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 362\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[0;32m    363\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\__init__.py:448\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 448\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[0;32m    449\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:392\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    390\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[0;32m    391\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[0;32m    393\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    394\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\html\\parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[0;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[0;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\html\\parser.py:337\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[0;32m    336\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_starttag(tag, attrs)\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m tag \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[0;32m    339\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:151\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m#print(\"START\", name)\u001b[39;00m\n\u001b[0;32m    150\u001b[0m sourceline, sourcepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetpos()\n\u001b[1;32m--> 151\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoup\u001b[39m.\u001b[39;49mhandle_starttag(\n\u001b[0;32m    152\u001b[0m     name, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, attr_dict, sourceline\u001b[39m=\u001b[39;49msourceline,\n\u001b[0;32m    153\u001b[0m     sourcepos\u001b[39m=\u001b[39;49msourcepos\n\u001b[0;32m    154\u001b[0m )\n\u001b[0;32m    155\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mand\u001b[39;00m tag\u001b[39m.\u001b[39mis_empty_element \u001b[39mand\u001b[39;00m handle_empty_element:\n\u001b[0;32m    156\u001b[0m     \u001b[39m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# events for tags of this name.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\__init__.py:716\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtagStack) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    712\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39mtext\n\u001b[0;32m    713\u001b[0m          \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39msearch_tag(name, attrs))):\n\u001b[0;32m    714\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melement_classes\u001b[39m.\u001b[39;49mget(Tag, Tag)(\n\u001b[0;32m    717\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder, name, namespace, nsprefix, attrs,\n\u001b[0;32m    718\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrentTag, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_most_recent_element,\n\u001b[0;32m    719\u001b[0m     sourceline\u001b[39m=\u001b[39;49msourceline, sourcepos\u001b[39m=\u001b[39;49msourcepos\n\u001b[0;32m    720\u001b[0m )\n\u001b[0;32m    721\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    722\u001b[0m     \u001b[39mreturn\u001b[39;00m tag\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\element.py:1210\u001b[0m, in \u001b[0;36mTag.__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39melif\u001b[39;00m attrs:\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m builder\u001b[39m.\u001b[39mcdata_list_attributes:\n\u001b[1;32m-> 1210\u001b[0m         attrs \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49m_replace_cdata_list_attribute_values(\n\u001b[0;32m   1211\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, attrs)\n\u001b[0;32m   1212\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1213\u001b[0m         attrs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(attrs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\NPL\\Lib\\site-packages\\bs4\\builder\\__init__.py:304\u001b[0m, in \u001b[0;36mTreeBuilder._replace_cdata_list_attribute_values\u001b[1;34m(self, tag_name, attrs)\u001b[0m\n\u001b[0;32m    301\u001b[0m universal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata_list_attributes\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, [])\n\u001b[0;32m    302\u001b[0m tag_specific \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata_list_attributes\u001b[39m.\u001b[39mget(\n\u001b[0;32m    303\u001b[0m     tag_name\u001b[39m.\u001b[39mlower(), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 304\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(attrs\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m universal \u001b[39mor\u001b[39;00m (tag_specific \u001b[39mand\u001b[39;00m attr \u001b[39min\u001b[39;00m tag_specific):\n\u001b[0;32m    306\u001b[0m         \u001b[39m# We have a \"class\"-type attribute whose string\u001b[39;00m\n\u001b[0;32m    307\u001b[0m         \u001b[39m# value is a whitespace-separated list of\u001b[39;00m\n\u001b[0;32m    308\u001b[0m         \u001b[39m# values. Split it into a list.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m         value \u001b[39m=\u001b[39m attrs[attr]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#code articles dataset\n",
    "import pandas as pd\n",
    "from scrape import get_articles_dataset\n",
    "article_df = get_articles_dataset('datasets/code_articles.csv')\n",
    "clean_article = {'X': [str(article) for article in article_df], 'Y': 'productive'}\n",
    "clean_article = pd.DataFrame(clean_article)\n",
    "\n",
    "print(clean_article.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Now I have to say \"Leroy can you please paint ...\n",
      "Name: body, dtype: object\n",
      "                                                        X             Y\n",
      "0       I hate how you cant even say black paint anymo...  unproductive\n",
      "1       What's the difference between a Jew in Nazi Ge...  unproductive\n",
      "2       I recently went to America.... ...and being th...  unproductive\n",
      "3       Brian raises his hand and says, “He’s in Heave...  unproductive\n",
      "4       You hear about the University book store worke...  unproductive\n",
      "...                                                   ...           ...\n",
      "194548  I like a girl with words tattooed on her back....  unproductive\n",
      "194549     I have sexdaily... I mean dyslexia fcuk!!! >_<  unproductive\n",
      "194550  What's the difference between a hippie chick a...  unproductive\n",
      "194551  new family robot A father buys a lie detector ...  unproductive\n",
      "194552  I went to a zoo and there was only one animal....  unproductive\n",
      "\n",
      "[194553 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#reddit jokes dataset\n",
    "reddit_jokes = pd.read_json('datasets/reddit_jokes.json')\n",
    "print(reddit_jokes['body'].head(1))\n",
    "clean_reddit_jokes = {\"X\":[str(reddit_jokes[\"title\"][i])+\" \"+str(reddit_jokes[\"body\"][i]) for i in range(reddit_jokes.shape[0])]}\n",
    "clean_reddit_jokes[\"Y\"] = [\"unproductive\" for i in range(reddit_jokes.shape[0])]\n",
    "clean_reddit_jokes = pd.DataFrame(clean_reddit_jokes)\n",
    "\n",
    "print(clean_reddit_jokes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'website_url', 'cleaned_website_text', 'Category'], dtype='object')\n",
      "                                                      X             Y\n",
      "0     official site good hotel accommodation big sav...  unproductive\n",
      "1     expedia hotel book sites like use vacation wor...  unproductive\n",
      "2     tripadvisor hotel book sites like previously d...  unproductive\n",
      "3     cheap flights search compare flights momondo f...  unproductive\n",
      "4     bot create free account create free account si...  unproductive\n",
      "...                                                 ...           ...\n",
      "1403  old nude women porn mature granny sex horny ol...  unproductive\n",
      "1404  bdsm cams bdsm chat bondage cams free bdsm vid...  unproductive\n",
      "1405  porno dvd online european porn dvd cheap adult...  unproductive\n",
      "1406  anal dream house anal dream house anal dream h...  unproductive\n",
      "1407  world sex news daily sex news adult news eroti...  unproductive\n",
      "\n",
      "[1408 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#website dataset\n",
    "\n",
    "website = pd.read_csv(\"datasets/website.csv\")\n",
    "print(website.columns)\n",
    "unproductiveSites = [\"Travel\", \"Social Networking and Messaging\", \"Streaming Services\", \"Sports\", \"Photography\", \"News\", \"Health and Fitness\", \"Games\", \"E-Commerce\", \"Forums\", \"Food\", \"Adult\"]\n",
    "\n",
    "clean_website = {\"X\":[str(website[\"cleaned_website_text\"][i]) for i in range(website.shape[0])]}\n",
    "for i in range(website.shape[0]):\n",
    "    if str(website[\"Category\"][i] in unproductiveSites):\n",
    "        clean_website[\"Y\"] = \"unproductive\"\n",
    "    else:\n",
    "        clean_website[\"Y\"] = \"productive\"\n",
    "\n",
    "clean_website = pd.DataFrame(clean_website)\n",
    "\n",
    "print(clean_website)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body',\n",
      "       'created', 'timestamp'],\n",
      "      dtype='object')\n",
      "                                                     X             Y\n",
      "0    [Discussion] Am I just late to some change, or...  unproductive\n",
      "1    [REQUEST] Shows similar to Only Murders in the...  unproductive\n",
      "2    [DISCUSSION] (US) The Fury of a Patient Man (T...  unproductive\n",
      "3    [US] Love Harder (2021): this year's Netflix C...  unproductive\n",
      "4    [DISCUSSION] Arcane (2021) Holy. Shit. This on...  unproductive\n",
      "..                                                 ...           ...\n",
      "457  [REQUEST] Rewatching the matrix series I just ...  unproductive\n",
      "458  [US] If I Leave Here Tomorrow: A Film About Ly...  unproductive\n",
      "459  [Request] K-Dramas or Korean movies \"as good a...  unproductive\n",
      "460  [Request] Documentaries like Fantastic Fungi &...  unproductive\n",
      "461  [REQUEST] Just finished Neon Genesis Evangelio...  unproductive\n",
      "\n",
      "[462 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "netflix = pd.read_csv(\"./datasets/Netflix.csv\")\n",
    "print(netflix.columns)\n",
    "clean_netflix = {\"X\":[str(netflix[\"title\"][i])+\" \"+str(netflix[\"body\"][i]) for i in range(netflix.shape[0])]}\n",
    "clean_netflix[\"Y\"] = [\"unproductive\" for i in range(netflix.shape[0])]\n",
    "clean_netflix = pd.DataFrame(clean_netflix)\n",
    "\n",
    "print(clean_netflix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   X             Y\n",
      "0  I hate how you cant even say black paint anymo...  unproductive\n",
      "1  What's the difference between a Jew in Nazi Ge...  unproductive\n",
      "2  I recently went to America.... ...and being th...  unproductive\n",
      "3  Brian raises his hand and says, “He’s in Heave...  unproductive\n",
      "4  You hear about the University book store worke...  unproductive\n"
     ]
    }
   ],
   "source": [
    "print(clean_reddit_jokes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      X             Y\n",
      "0     [Discussion] Am I just late to some change, or...  unproductive\n",
      "1     [REQUEST] Shows similar to Only Murders in the...  unproductive\n",
      "2     [DISCUSSION] (US) The Fury of a Patient Man (T...  unproductive\n",
      "3     [US] Love Harder (2021): this year's Netflix C...  unproductive\n",
      "4     [DISCUSSION] Arcane (2021) Holy. Shit. This on...  unproductive\n",
      "...                                                 ...           ...\n",
      "1865  old nude women porn mature granny sex horny ol...  unproductive\n",
      "1866  bdsm cams bdsm chat bondage cams free bdsm vid...  unproductive\n",
      "1867  porno dvd online european porn dvd cheap adult...  unproductive\n",
      "1868  anal dream house anal dream house anal dream h...  unproductive\n",
      "1869  world sex news daily sex news adult news eroti...  unproductive\n",
      "\n",
      "[1870 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([clean_netflix, clean_website], ignore_index=True)\n",
    "print(result)\n",
    "result.to_csv(\"dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
